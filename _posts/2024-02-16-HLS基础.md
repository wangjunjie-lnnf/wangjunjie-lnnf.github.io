---
layout: post
title:  "HLSåŸºç¡€"
date:   2024-02-16 00:47:07 +0000
categories: jekyll
tags: hardware
---

# HLSåŸºç¡€

> The promise of high-level synthesis (HLS) is a powerful one: the ability to generate production quality register transfer level (RTL) implementations from high-level specifications. In other words, HLS automates an otherwise manual process, eliminating the source of many design errors and accelerating a very long and iterative part of the development cycle.

HLSçš„è¿‡ç¨‹ç±»ä¼¼æ™®é€šçš„C/C++ç¼–è¯‘æˆæ±‡ç¼–è¯­è¨€çš„è¿‡ç¨‹ï¼Œåªæ˜¯å¯¹æ­¤å¤„çš„C/C++æœ‰ä¸€äº›ç‰¹æ®Šè¦æ±‚ï¼Œç¼–è¯‘çš„ç»“æœä¹Ÿä¸æ˜¯æ±‡ç¼–è¯­è¨€ï¼Œè€Œæ˜¯æ›´åº•å±‚çš„ç¡¬ä»¶æè¿°è¯­è¨€Verilog/VHDL


## Data Types

> The need for bit-accuracy becomes especially obvious now that designers are building hardware directly from C++, whose native types only come in widths of 1, 8, 16, 32, etc, bits. To date there are two industry standard bit accurate data types, the `SystemC` and `Mentor Graphics Algorithmic C` data types. Although SystemC was developed first, the implementation of its bit-accurate data types suffers from a number of issues, the biggest being long execution runtimes. Because of this, customer demand drove Mentor to develop their own bit-accurate types, which have now become the most widely used data types in high-level synthesis. The Algorithmic C data types not only simulate much faster than the SystemC types, but give better quality of results for synthesis over â€œhome grownâ€ bit accurate types. Algorithmic C data types are also consistent between C++ and RTL simulation. So whatever you build in C++ matches the true hardware behavior. 

C/C++åŸç”Ÿçš„æ•°æ®ç±»å‹bité•¿åº¦æ˜¯ç‰¹å®šçš„ï¼Œé«˜æ•ˆçš„æè¿°ç¡¬ä»¶è¡Œä¸ºéœ€è¦bitç²¾ç¡®çš„æ•°æ®ç±»å‹ï¼Œä¸»æµçš„bitç²¾ç¡®çš„æ•°æ®ç±»å‹åŒ…æ‹¬`SystemC`å’Œ`Algorithmic C`ï¼Œ`Algorithmic C`ä»¿çœŸæ•ˆç‡æ›´é«˜ã€ç»¼åˆç»“æœæ›´å¥½ã€‚

æ•´æ•°æ•°æ®ç±»å‹: `ac_int<W, S>`ï¼ŒWè¡¨ç¤ºå®½åº¦ï¼ŒSè¡¨ç¤ºç¬¦å·

```C++
// Algorithmic-Cå¤´æ–‡ä»¶
#include <ac_int.h>

// 3-bitçš„æ— ç¬¦å·æ•°
ac_int<3, false> x;

// 5-bitçš„æœ‰ç¬¦å·æ•°
ac_int<5, true> y;
```

å®šç‚¹æ•°æ®ç±»å‹: `ac_fixed<W, I, S>`ï¼ŒWè¡¨ç¤ºæ€»å®½åº¦ï¼ŒIè¡¨ç¤ºæ•´æ•°å®½åº¦ï¼ŒSè¡¨ç¤ºç¬¦å·

```C++
// Algorithmic-Cå¤´æ–‡ä»¶
#include <ac_fixed.h>

// æ€»é•¿7-bitä¸”æ•´æ•°éƒ¨åˆ†3-bitçš„æ— ç¬¦å·å®šç‚¹æ•°
ac_fixed<7, 3, false> x;

// æ€»é•¿7-bitä¸”æ•´æ•°éƒ¨åˆ†3-bitçš„æœ‰ç¬¦å·å®šç‚¹æ•°
ac_fixed<7, 3, true> y;
```

---

`ac_int`å’Œ`ac_fixed`æ”¯æŒæ‰€æœ‰æ ‡å‡†çš„C++ç®—æœ¯å’Œé€»è¾‘æ“ä½œç¬¦

* **Bitwise Arithmetic Operators: *, +, -, /, &, |, ^, %** The `Algorithmic C` bitwise arithmetic operators are designed so that there is no loss of precision in the return value. Furthermore the mixture of signed and unsigned Algorithmic C data types is supported, and returns the expected signedness. The return type of an arithmetic operation automatically takes care of bit growth so that there is no loss of precision. This can be done automatically because the bit widths of the two operands are specified as template parameters when the `ac_int` variables are declared. 

ç®—æœ¯æ“ä½œä¸ä¼šå¯¼è‡´ç²¾åº¦ä¸¢å¤±ï¼Œæ”¯æŒæœ‰ç¬¦å·æ•°å’Œæ— ç¬¦å·æ•°æ··åˆ

```C++
ac_int<8,true> a,b; //8-bits signed

// Multiplying â€œaâ€ times â€œbâ€, each with 8 bits of precision, requires 16 bits of precision:
(returns ac_int<16,true>)(a*c)

// Adding â€œaâ€ plus â€œbâ€ requires nine bits of precision:
(returns ac_int<9,true>)(a+b)
```

* **Bit Select Operator: []** Individual bits can be read or written from an `ac_int` or `ac_fixed` data type using the `[]` operator. The operator index selects the bit position. E.g. `x[1], x[3], x[7]`. The return value is an object of class `ac_int::bitref` and a built-in conversion function to ac_int and bool are provided. 

```C++
ac_int<11,true> x;

// éšå¼è½¬æ¢ä¸ºbool
bool is_neg; = x[10];

// ç›´æ¥æ›´æ–°æŒ‡å®šbit
x[8] = 1;
```

* **Shift Operators: <<, >>** æ”¯æŒæœ‰ç¬¦å·æ•°å’Œæ— ç¬¦å·æ•°

```C++
ac_int<4,false> x = -1;     // set all bits to 1's
ac_int<4,false> y = x >> 2; // y=3

// æœ‰ç¬¦å·æ•°å³ç§»å¡«å……ç¬¦å·ä½
ac_int<4,true> x = 0;
x[3] = 1                    // set x equal -8
ac_int<4,true> y = x >> 2;  // y=-2
```

---

The Algorithmic C data types provide a number of built-in methods.

```C++
ac_int<8,false> x = 100;

// slice read: ä»ç´¢å¼•2å¼€å§‹å–3ä¸ªbit
ac_int<3,false> y = x.slc<3>(2);

// æŠŠyæ”¾åˆ°xç´¢å¼•2çš„ä½ç½®
x.set_slc(2, y);


ac_fixed<8,3,false> x = 3.185;

// to_int()å–æ•´æ•°éƒ¨åˆ†
ac_int<8,false> y = x.to_int();

// ac_intè½¬int
printf("%d\n", y.to_int());
```

## ç¼–ç è§„èŒƒ

> Starting the HW design from an untimed behavioral description is like drawing a picture on a new canvas. The painter might have the idea of what to paint in his mind, but not know exactly how to accomplish it. In HLS, the question is how to generate the desired hardware from an untimed description that does not even have a clock or rest. This is one of the main benefits, but also drawback of HLS. It allows to generate functionally equivalent circuits, but with very different underlining structures and hence, different area, performance and power trade-offs from the same description. This is done by setting different HLS synthesis options. The designer has to fully understand all of these synthesis options and how they interact with each other.

æ ¹æ®æ— æ—¶åºçš„C/C++ç”Ÿæˆç¡¬ä»¶ç”µè·¯å¥½æ¯”æ˜¯åœ¨ç™½çº¸ä¸Šç”»ç”»ï¼Œå¿ƒé‡Œæ¸…æ¥šè¦ç”»ä»€ä¹ˆå´æ— ä»ä¸‹æ‰‹ã€‚HLSæä¾›äº†å¾ˆå¤šç»¼åˆé€‰é¡¹ï¼Œåªæœ‰ç†è§£äº†è¿™äº›é€‰é¡¹å¯¹ç”Ÿæˆçš„ç”µè·¯çš„å½±å“ï¼Œæ‰èƒ½æ›´å¥½çš„è¡¨è¾¾ç›®æ ‡ç”µè·¯ã€‚

> HLS vendors provide an arsenal of optimizations that you can use. This should enable you to generate the desired hardware circuit. We call these options synthesis knobs and classify them into three different groups:

* **Global Synthesis Options (ğ‘˜ğ‘›ğ‘œğ‘<sub>ğ‘œğ‘ğ‘¡ğ‘ </sub>):** These are HLS options that are applied to the entire behavioral description to be synthesized. These include how to encode the FSM, synthesis frequency and synthesis mode.

* **Local Synthesis Directives (ğ‘˜ğ‘›ğ‘œğ‘<sub>ğ‘ğ‘Ÿğ‘ğ‘”ğ‘šğ‘</sub>):** These synthesis directives specify how to synthesize individual operations in the behavioral description. Vendors use pragmas (comments) for these. They allow to e.g., control how to synthesize individual arrays, functions and memories.

* **Functional Unit Constraint (ğ‘˜ğ‘›ğ‘œğ‘<sub>ğ¹ğ‘ˆğ‘ </sub>):** This knob allows the HLS user to control how many FUs the final circuit should have. These include adders, multipliers and dividers of different bitwidths.

HLSç¼–è¯‘å™¨æä¾›äº†å¾ˆå¤šé€‰é¡¹ï¼Œåˆ†ä¸ºä¸‰ç±»ï¼šå…¨å±€å‚æ•°ï¼›å±€éƒ¨æŒ‡ä»¤ï¼›FUçº¦æŸ

> It should be noted that every HLS tool has its own set of default options. This implies that the same behavioral description will lead to a very different circuit when synthesized using a different HLS tool. Some tools by default fully parallelize the description, while other tools do not perform any optimization. It is therefore important to understand how as a HLS user you can generate the smallest possible hardware circuit that meets your performance and power constraints.

é€‰é¡¹æ˜¯ç¼–è¯‘å™¨ç‰¹å®šçš„ï¼Œæ²¡æœ‰ç»Ÿä¸€è§„èŒƒ


### HLS Synthesis Knobs     

> **Global Synthesis Options (ğ‘˜ğ‘›ğ‘œğ‘<sub>ğ‘œğ‘ğ‘¡ğ‘ </sub>)** are options normally specified in a synthesis script and apply to the entire behavioral description to be synthesized. Some of these global options include how to synthesize loops, arrays, and functions, similar to the local synthesis directives, but are applicable to all of the loops, arrays, and functions in the behavioral description at the same time. With these global synthesis options, there is no way to specify different options for individual operations. For example, in the case of loops, all loops will be unrolled or not unrolled, but there is no way to unroll some of the loops, pipeline others and not unrolled some other loops in the description. Other options which are complementary to the local synthesis directives include the synthesis mode, clock constraint, data initiation interval (DII) for pipelined designs, encoding scheme for the finite state machine (FSM) controller (one-hot, regular encoding), etc. 

å…¨å±€é€‰é¡¹å’Œå±€éƒ¨æŒ‡ä»¤éƒ¨åˆ†äº’æ–¥éƒ¨åˆ†äº’è¡¥

> Most commercial HLS tools make extensive use of synthesis directives in the form of pragmas . These pragmas are inserted directly at the behavioral description in the form of comments. This has the main advantage of allowing a very fine controllability over the synthesis result and hence the final micro-architecture. **The main constructs in the behavioral description that have the highest impact on the final microarchitecture in HLS are loops, arrays and functions**. Loops can be completely unrolled or only partially unrolled. Loops can also be pipelined (folded) with different Data Initiation Intervals (DIIs). Arrays can be mapped to registers or memories of different types and ports and functions can be inlined or not.

```C++
/* pragma unroll= 0 | partial | all | fold */
for(x=0; x<8; x++)
```

å¯¹ç»¼åˆç»“æœå½±å“æœ€å¤§çš„ç»“æ„æ˜¯ï¼šå¾ªç¯ã€æ•°ç»„ã€å‡½æ•°ã€‚å¾ªç¯å¯ä»¥å®Œå…¨å±•å¼€æˆ–éƒ¨åˆ†å±•å¼€ï¼›å¾ªç¯ä¹Ÿå¯ä»¥é€šè¿‡ç®¡é“å®ç°å¹¶è¡Œï¼›æ•°ç»„å¯ä»¥æ˜ å°„åˆ°å¯„å­˜å™¨æˆ–ä¸åŒç±»å‹å’Œç«¯å£çš„å†…å­˜ï¼›å‡½æ•°å¯ä»¥é€‰æ‹©æ˜¯å¦inlineã€‚

> The number of Functional Units (FUs) allowed will affect the parallelism that can be extracted from the behavioral description. A well-known optimization technique called resource sharing can be used in order to reduce the area. In resource sharing, a single FU is reused among different computational operations in the behavioral description. For ASICs, the total design area can be significantly reduced as HLS can easily maximize the amount of resource sharing. In contrast, it was also shown that for FPGAs, resource sharing can actually lead to larger designs. This is mainly because the multiplexers required to share individual FUs have shown to require more logic resources than the actual FUs being shared. Commercial ASIC-style HLS tools typically perform resource-constraint HLS. This implies that the first stage in the HLS process is the resource allocation stage, which outputs a functional unit constraint file (FCNT) . This constraint file can in turn be edited to allow the designer to control the amount of resource sharing desired, which in turn leads to a micro-architecture of unique area vs. performance trade-off. This constraint set by the user delimits the maximum number of FUs that the HLS process can use, but does not imply that all of those resources will end up being used, as this constraint only specifies the upper bound of FUs that can be used. Depending on the other two knobs, less adders might be required, but under no circumstances, the HLS tool should use more FUs than specified by the user.

FUçš„æ•°é‡å½±å“å¯ä»¥å¹¶è¡Œçš„ç¨‹åº¦ï¼Œå¸¸è§çš„ä¼˜åŒ–æŠ€æœ¯æ˜¯èµ„æºå…±äº«ï¼Œä¸€ä¸ªFUåœ¨ä¸åŒçš„å‘¨æœŸè¢«ä¸åŒçš„è®¡ç®—ä½¿ç”¨ï¼Œå¯¹ASICæ¥è¯´å¯ä»¥è¾ƒå°é¢ç§¯ï¼Œå¯¹äºFPGAæ¥è¯´ç”±äºå…±äº«è€Œäº§ç”Ÿå¤§é‡multiplexerä»è€Œå¯¼è‡´åä½œç”¨ã€‚

> Out of all three knobs, the local synthesis directives knob is the most powerful one as it basically decides upon the overall underlying microarchitecture. Commercial synthesizers also typically give priority to local synthesis directives when global synthesis options with opposing effects have been specified. It should be noted that these knobs are complementary, but also largely overlapping. E.g., a loop will not be fully unrolled if the number of functional units does not allow it. This shows how important it is to fully understand the consequences of limiting the number of FUs when specifying synthesis directives. 

å±€éƒ¨æŒ‡ä»¤å¯¹ç»¼åˆç»“æœå½±å“æœ€å¤§ï¼Œå½“å’Œå…¨å±€å‚æ•°äº§ç”Ÿå†²çªæ—¶ï¼Œä¸€èˆ¬å±€éƒ¨æŒ‡ä»¤ä¼˜å…ˆçº§è·Ÿé«˜ï¼Œå±€éƒ¨æŒ‡ä»¤æœ€ç»ˆä¹Ÿè¦å—å¯ç”¨èµ„æºçš„çº¦æŸã€‚


### Synthesis Mode

![hls-mode](/assets/images/2024-02-16/hls-mode.png)

> The synthesis mode is a global synthesis option that enables the synthesis of applications with different characteristics. Most HLS tool vendors provide different synthesis engines under their hood. 

ç»¼åˆæ¨¡å¼æ˜¯ä¸€ä¸ªå…¨å±€å‚æ•°ï¼Œç”¨äºå¤„ç†ä¸åŒçš„åº”ç”¨ç±»å‹ã€‚


> Most applications can be classified into one of these three families: 

* **Data intensive applications:** These are the most common applications used with HLS and include arithmetic intensive applications like DSP and video processing applications. They might also involve computationally intensive applications with little control structures like encryption algorithms, but that have large amounts of parallelism.

* **Control intensive applications:** These applications are also arithmetic intensive, but contain also many control structures like nested if-else conditions. In the past, these type of applications were not suitable for HLS, because the HLS tools were not able to extract enough parallelism from these applications to justify a dedicated hardware accelerator. Modern HLS tools make use of complex compiler optimizations like `different types of speculations` that allows to much better parallelize these applications.

* **Controllers or bus interfaces:** This category of applications include bus controllers that have very specific protocols which require specific timing that needs to be satisfied. Some HLS tools cannot synthesize these types of applications as regular C/C++ has no timing notion, while other HLS tools provide extensions in their C languages to deal with this.

åº”ç”¨ä¸€èˆ¬åˆ†ä¸ºï¼šæ•°æ®æ•æ„Ÿåº”ç”¨ï¼›æ§åˆ¶æ•æ„Ÿåº”ç”¨ï¼›æ§åˆ¶å™¨æˆ–æ€»çº¿æ¥å£ã€‚æ•°æ®æ•æ„Ÿåº”ç”¨æ˜¯HLSæœ€å¸¸è§çš„åº”ç”¨ï¼ŒåŒ…å«å¤§é‡å¹¶è¡Œè®¡ç®—å’Œå°‘é‡æ§åˆ¶ç»“æ„ï¼›æ§åˆ¶æ•æ„Ÿåº”ç”¨åŒ…å«å¤§é‡`if-else`ç»“æ„ï¼›æ§åˆ¶å™¨æˆ–æ€»çº¿æ¥å£å®ç°ç‰¹å®šçš„åè®®ã€‚


> HLS vendors might include different HLS engines to deal with all of these applications

* **Automatic Synthesis Mode** Automatic synthesis mode is the traditional HLS synthesis mode. It is also what most people identify with HLS. The result of this process is an `FSM+Data path` where new inputs are read in state X and a new output is written in state Z.

* **Pipeline Synthesis Mode** For many multi-media applications throughput is very important. To achieve higher throughputs the hardware has to be fully pipelined. Pipelines function like a factory with multiple different stages allowing data to be fed into the pipeline every clock cycle, or every N clock cycles, based on the Data Initialization Interval (DII).

![hls-pipelined-cpu](/assets/images/2024-02-16/hls-pipelined-cpu.png)

> Pipelining is a well-known parallelization optimization that allows to parallelize the execution of any application. Figure above shows a typical 5-stage pipelined CPU architecture. The key that enables pipelining is the pipeline latches that allow to de-couple the different combinational portions of the circuit into unique pipeline stages.

ç®¡é“å°±åƒå·¥å‚çš„æµæ°´çº¿ï¼Œæ˜¯å¸¸ç”¨çš„ä¼˜åŒ–æ–¹æ³•ï¼Œä¸Šå›¾æ˜¯ä¸€ä¸ªå…¸å‹çš„5é˜¶æ®µç®¡é“çš„cpuæ¶æ„ï¼Œç®¡é“çš„å…³é”®æ˜¯è§£è€¦ä¸åŒçš„éƒ¨åˆ†åˆ°ç‹¬ç«‹çš„é˜¶æ®µ


> Thus, if throughput is important (e.g., in multimedia applications), then the HLS user might need to fully pipeline the circuit. This requires that the user specifies that the circuit should be pipelined and also the DII. DII basically specifies after how many clock cycles a new input is entering the pipeline. It thus, also determines the interval at which a new output is generated. E.g., if DII=1, then a new input enters the pipeline every clock cycle and when the pipeline is in steady operation mode, an output is generated every clock cycle too. 

ç®¡é“æœ‰ä¸€ä¸ªé‡è¦å‚æ•°DIIï¼ŒDIIæŒ‡å®šä¸¤ä¸ªè¾“å…¥é—´éš”çš„æ—¶é’Ÿå‘¨æœŸæ•°é‡


* **Manual Synthesis Mode** Manual synthesis mode involves manually scheduling the behavioral description instead of relying on the HLS engine to do this. Some HLS tools allow to manually schedule the entire behavioral description, while other tools also allow to schedule a portion of the behavioral description, typically the IOs so that the data can be read and written into the hardware module following a particular protocol.

![hls-manual-mode](/assets/images/2024-02-16/hls-manual-mode.png)

ä¸Šå›¾ä¸­`$`è¡¨ç¤ºæ—¶é’Ÿè¾¹ç•Œï¼Œç”¨æˆ·å¯ä»¥ä»¥æ­¤è‡ªç”±æ§åˆ¶æ—¶é’Ÿè¾¹ç•Œå®ç°ä»»ä½•åè®®ï¼Œé€‚ç”¨äºæ§åˆ¶å™¨æˆ–æ€»çº¿æ¥å£ç±»åº”ç”¨


### Loop Synthesis

> One of the most widely used constructs in any high-level language are loops . These can be synthesized in many different ways. Thus, it is important to understand the effect of these loop synthesis options on the area and performance of the final circuit.

![hls-loop](/assets/images/2024-02-16/hls-loop.png)

> Figure above shows the different ways to synthesize loops in HLS and their trade-offs in terms of the area of the resultant circuit, the performance (in latency) and also the HLS synthesize time. As shown, fully unrolling the loop leads to the fastest of all the circuits, but also the largest, not unrolling the loop implies to sequentially execute each loop iteration like a CPU and hence, leading to a smaller circuit, but slower, while partially unrolling the loop with different unrolling factors lead to intermediate results.

å¾ªç¯å®Œå…¨å±•å¼€å»¶è¿Ÿæœ€å°é¢ç§¯æœ€å¤§ï¼Œå¾ªç¯é¡ºåºè¿­ä»£å»¶è¿Ÿæœ€é«˜é¢ç§¯æœ€å°

æœ‰ä¸¤ç§æ–¹å¼æ§åˆ¶å¾ªç¯å±•å¼€ï¼šå…¨å±€å‚æ•°å’Œå±€éƒ¨æŒ‡ä»¤ï¼Œå±€éƒ¨æŒ‡ä»¤æ›´çµæ´»ï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š

```C++
int data[16];

int ave8(int data_new){
    int sum=0, x;

    /* pragma unroll=all*/
    for(x=7; x>0; x--)
        data[x]=data[x-1];

    data[0]= data_new;

    /* pragma unroll=0|=4|=all*/
    for(x=0; x<8; x++)
        sum=sum+data[x];

    return(sum/8);
}
```

![hls-loop-example](/assets/images/2024-02-16/hls-loop-example.png)

ä¸Šå›¾å±•ç¤ºäº†ä¸åŒçš„å±•å¼€æ–¹å¼ç”Ÿæˆçš„ç”µè·¯ï¼Œå®Œå…¨ä¸å±•å¼€æ—¶éœ€è¦ä¸€ä¸ªåŠ æ³•å’Œ8ä¸ªå‘¨æœŸï¼›å®Œå…¨å±•å¼€æ—¶éœ€è¦7ä¸ªåŠ æ³•å’Œ1ä¸ªå‘¨æœŸã€‚


> These results obviously also depend on how the array is synthesized as it assumes that all of the elements in the array can be accessed in parallel. This is not the case if the array is synthesized as a single port memory. It is therefore extremely important to understand how to synthesize arrays.

æ­¤ä¾‹ä¸­å¾ªç¯çš„å±•å¼€æ–¹å¼åŒæ—¶å—æ•°ç»„çš„ç»¼åˆæ–¹å¼çš„å½±å“


### Array Synthesis

![hls-array](/assets/images/2024-02-16/hls-array.png)

å¯„å­˜å™¨å»¶è¿Ÿæ›´å°ä½†æ˜¯éœ€è¦æ›´å¤šæ™¶ä½“ç®¡

| Option | Description |
| - | - |
ROM     | Read-only memory
Logic   | Hard-coded logic for read-only array
RAM     | Memory, can have multiple ports
Register | Register bank with multiple ports
Expand  | Expand array to individual FFs

> Table above highlights the most common ways to synthesize arrays classified in whether they are read-only or not. Read-only arrays (arrays that have been initialized and are only read from) can be synthesized as ROMs or pure combinational logic. Read/Write arrays can be synthesized as RAM, registers or be expanded into individual FFs. Many of these synthesis options have sub-options, like e.g., in the RAM case, the user can decide how many ports the memory should have. In the case of multi-dimensional arrays HLS tools also offer ways to partition this array in different dimensions, leading to different memory configurations.

æ•°ç»„ç»¼åˆæˆRAMæˆ–Registeræ—¶å¯ä»¥æŒ‡å®šè¯»å†™ç«¯å£æ•°é‡ï¼Œå¤šç»´æ•°ç»„å¯ä»¥æŒ‡å®šåˆ†å‰²æ–¹å¼

### Functions Synthesis

![hls-function](/assets/images/2024-02-16/hls-function.png)

| Option | Description |
| - | - |
inline  | Every function call is synthesized as its own HW block
operator | Function is encapsulated as FU. User determines how many.
goto    | Single HW block for every function call

> Inlining basically instantiates as separate individual hardware blocks every time that the function is called. Goto does the opposite. A single hardware block is synthesized for that function. Operator on the other hand is a trade-off between both extremes that allows users to control that area vs. performance trade-offs. Basically, the function is encapsulated as a FU and the user can specify in the FU constraint file how many functions it allows the synthesizer to instantiate.

inlineå‡½æ•°æ¯æ¬¡è¢«è°ƒç”¨éƒ½ä¼šç”Ÿæˆé‡å¤çš„ç”µè·¯ï¼›gotoæ¨¡å¼ä¸ºæ¯ä¸ªå‡½æ•°åªç”Ÿæˆä¸€ä¸ªç”µè·¯ï¼Œæ¯ä¸ªæ—¶é’Ÿå‘¨æœŸæ¯ä¸ªå‡½æ•°æœ€å¤šè°ƒç”¨ä¸€æ¬¡ï¼›operatoræ¨¡å¼å¯ä»¥æŒ‡å®šä¸ºæ¯ä¸ªå‡½æ•°ç”Ÿæˆå‡ ä¸ªç”µè·¯ï¼Œä½œä¸ºFUçº¦æŸæ¯ä¸ªæ—¶é’Ÿå‘¨æœŸå¯ä»¥è°ƒç”¨çš„æ¬¡æ•°


## HLSç¼–è¯‘å™¨

æ­¤èŠ‚ç»“åˆå¼€æºHLSç¼–è¯‘å™¨[bambu](https://github.com/ferrandi/PandA-bambu.git)æè¿°HLSç¤ºä¾‹




