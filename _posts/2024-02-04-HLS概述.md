---
layout: post
title:  "HLSæ¦‚è¿°"
date:   2024-02-04 22:22:07 +0000
categories: jekyll
tags: hardware
---

# HLSæ¦‚è¿°

> HLS can be defined as: **The process of converting an untimed or partially timed behavioral description into efficient hardware.** You can think of the process of converting ANSI-C, C++ or MATLAB into a synthesizable low-level Hardware Description Language (HDL) like Verilog or VHDL. I include in the definition partially timed behavioral description because many commercial HLS tools allow to time different portions of the behavioral description. This allows HLS user to e.g., model hardware interfaces.

> é«˜çº§ç»¼åˆçš„å®šä¹‰æ˜¯æŠŠæ— æ—¶åºæˆ–éƒ¨åˆ†æ—¶åºçš„è¡Œä¸ºæè¿°è½¬æ¢ä¸ºé«˜æ•ˆçš„ç¡¬ä»¶æè¿°ã€‚ä¾‹å¦‚æŠŠC/C++è¯­è¨€æè¿°çš„è¡Œä¸ºè½¬æ¢ä¸ºä½çº§ç¡¬ä»¶æè¿°è¯­è¨€Verilogæˆ–VHDLã€‚

![hls-overview](/assets/images/2024-02-04/hls-overview.png)

> In particular the inputs to any HLS process are the following:

* **Behavioral Description (ğ¶<sub>ğ‘–ğ‘›</sub>)** This is the behavioral description to be converted into a hardware circuit through HLS. Different HLS vendors support different input languages. The most common ones are ANSI-C, C++, SystemC (C++ class for hardware design) or MATLAB.

* **Synthesis Directives (ğ‘ğ‘Ÿğ‘ğ‘”ğ‘šğ‘<sub>ğ»ğ¿ğ‘†</sub>)** These are comments inserted in the behavioral description that allows the designer to control how to mainly synthesize arrays, loops and functions. These directives are extremely important in order to generate the hardware circuit with the desired constraints.

* **Technology Library (ğ‘¡ğ‘’ğ‘â„ğ‘™ğ‘–ğ‘<sub>ğ»ğ¿ğ‘†</sub>)** HLS requires a technology library that includes the area and delay of basic operators like adders, multipliers, multiplexers, etc. This library is extremely important to get good results. 

* **Target Synthesis Frequency (ğ‘“<sub>ğ»ğ¿ğ‘†</sub>)** The designer has to specify the target frequency at which the generated hardware needs to run as an input to the HLS process.

> The HLS process reads in all of these inputs and performs three main steps: (1) Resource allocation, (2) scheduling and (3) binding. 

> HLSçš„è¾“å…¥ä¿¡æ¯åŒ…æ‹¬ï¼šä½¿ç”¨C/C++/SystemCæè¿°çš„è¡Œä¸ºï¼›ç»¼åˆæŒ‡ä»¤ï¼›æŠ€æœ¯åº“ï¼›ç›®æ ‡ç»¼åˆé¢‘ç‡ã€‚åŸºäºè¾“å…¥ä¿¡æ¯æ‰§è¡Œ3ä¸ªæ­¥éª¤ï¼šèµ„æºåˆ†é…ï¼›è°ƒåº¦ï¼›ç»‘å®šã€‚

---

> The HLS process finally generates the hardware circuit specified in the selected HDL (Verilog or VHDL). In addition, the HLS process typically also generates additional outputs, In particular:

* **Register Transfer Level Description (RTL)** This is the main output of the HLS process. The hardware circuit described using a HDL. In the figure every point in the trade-off curve represents a unique RTL description with different area vs. performance trade-offs. This is one of the advantages of HLS compared to using low-level HDLs. Changing e.g., the synthesis directives the HLS process will generate a different circuit.

* **Quality of Results (QoR) Report** HLS tools also report the results in terms of estimated area, performance, critical path delay and often power. It should be noted that the values reported after HLS are only approximated values and should be interpreted with caution.

* **Logic Synthesis Scripts** HLS is the first step in a series of additional steps required to build a complete hardware circuit. Thus, most HLS tools generate scripts to interface the HLS tool with the logic synthesis tool. These can be Application Specific Integrated Circuit (ASIC) or Field-Programmable Gate Array (FPGA) logic synthesis tools, as the RTL code needs to be further synthesized into a gate netlist.

* **Testbench** The generated RTL code although correct by construct needs to always be verified. Thus, most HLS tools also generated testbenches as an output.

> HLSçš„äº§å‡ºç‰©åŒ…æ‹¬ï¼šåŸºäºVerilogæˆ–VHDLçš„RTLçº§æè¿°ï¼›å…³äºé¢ç§¯ã€æ€§èƒ½ã€èƒ½è€—çš„è´¨é‡æŠ¥å‘Šï¼›é€‚ç”¨äºASICæˆ–FPGAçš„é€»è¾‘ç»¼åˆè„šæœ¬ï¼›æµ‹è¯•ç”¨ä¾‹ã€‚


## èƒŒæ™¯

![hls-soc](/assets/images/2024-02-04/hls-soc.png)

> With the advent of Mooreâ€™s law, most Integrated Circuits (ICs) are now heterogeneous System-on-Chip (SoCs). These SoCs contain a variety of different embedded processor, embedded memory, different peripherals (e.g., UART, SPI, I2C) and a multiple dedicated hardware accelerators (HWaccs), all interconnected through an on-chip bus.

> æ ¹æ®æ‘©å°”å®šå¾‹ï¼Œé›†æˆç”µè·¯å·²ç»æ¼”å˜ä¸ºå¤§å‹çš„SOCï¼ŒåŒ…å«å„ç§åµŒå…¥å¼å¤„ç†å™¨ã€åµŒå…¥å¼å†…å­˜ã€å„ç§å¤–è®¾å’Œç¡¬ä»¶åŠ é€Ÿå™¨ï¼Œéƒ½é€šè¿‡ç‰‡ä¸Šæ€»çº¿ç›¸è¿ã€‚

> One of the reasons why HLS is a good choice when designing these accelerators is that the applications to be accelerated in HW are often first developed using a high-level language such as ANSI-C, C++ or MATLAB. Some of these applications include encryption algorithms, Digital Signal Processing (DSP), image processing applications and more recently different types of Artificial Neural Networks (ANNs) to name a few. The main characteristics of any application to be accelerated is that it should have large amounts of parallelism so that the dedicated hardware implementation can be faster and more energy efficient than executing it on the embedded SoC processor. It seems therefore natural to use HLS to directly synthesize any of these applications into a dedicated HW accelerator using HLS instead of having to manually translate the algorithm from the original behavioral description into RTL.

> SOCä¸­çš„åŠ é€Ÿå™¨ä¸€èˆ¬éƒ½æ˜¯é¦–å…ˆåŸºäºC/C++å¼€å‘çš„ï¼Œå¦‚æœå…¶ä¸­åŒ…å«å¤§é‡å¯å¹¶è¡Œéƒ¨åˆ†ï¼Œæ”¹ä¸ºç¡¬ä»¶å®ç°å¯å¤§å¹…æé«˜æ€§èƒ½ã€‚ä¸ä½¿ç”¨HDLé‡æ–°å®ç°åŠ é€Ÿé€»è¾‘ç›¸æ¯”ï¼Œç›´æ¥å°†C/C++è½¬æ¢ä¸ºHDLæ•ˆç‡æ›´é«˜ã€‚


## ä¼˜åŠ¿

![hls-vs-verilog](/assets/images/2024-02-04/hls-vs-verilog.png)

> Raising the level of HW design abstraction from the RT-level (Verilog or VHDL) to the behavioral level has multiple advantages: 

* **Faster and Easier Design** Writing C/C++ code is much easier than writing Verilog or VHDL. It requires less lines of code as C/C++ does not require to specify many things that are needed in any HDL. Some include the clock and the reset.

* **Faster Verification** Starting at the untimed behavioral level also allows us to speed up the verification process as different types of simulation models at the different abstraction levels can be leveraged. E.g., the untimed C/C++ description can be compiled using a regular SW compiler like gcc or g++ leading to simulation speeds of 1MHz. HLS also allows to generate fast cycle-accurate simulation model. These are again 10Ã— faster than an RTL simulation and are timing accurate.

* **Ability to generate Functional Equivalent Designs** One additional and unique advantage of HLS is that it allows to generated a variety of functional equivalent hardware implementations from the same behavioral description by simply setting different HLS synthesis options. One of the inputs to the HLS process are the synthesis directives in the form of pragmas. Setting different combinations of these pragmas lead to designs with different area vs. performance and power trade-offs. Using low-level HDLs for HW designs implies that the micro-architecture of the HW is fixed. This implies that the area and performance are fixed. Generating a new architecture with different trade-offs would involve having to fully design and verify the RTL. This is time-consuming and error prone.

> HLSæ¯”HDLçš„æŠ½è±¡çº§åˆ«è·Ÿé«˜ï¼Œå› æ­¤å¼€å‘æ•ˆç‡å’Œä»¿çœŸéªŒè¯æ•ˆç‡éƒ½æ›´é«˜ï¼ŒHLSçš„ä¸€ä¸ªæ›´å¤§çš„ä¼˜åŠ¿æ˜¯é€šè¿‡æŒ‡å®šä¸åŒçš„å‚æ•°å¯ä»¥å¾—åˆ°ä¸åŒâ€œé¢ç§¯/æ€§èƒ½/èƒ½è€—â€ä½†æ˜¯åŠŸèƒ½ç›¸åŒçš„ç”µè·¯ã€‚


## HLSå®ç°

![hls-stages](/assets/images/2024-02-04/hls-stages.png)

> The process of converting an untimed behavioral description into structural synthesizable RTL code has been well studied since the 80â€™s. The complete process composed of three main stages

* **Stage 1: Front-end:** is the synthesizer front-end. Its main purpose is to check for syntactical errors in the behavioral description and to perform technology independent optimizations. These are common optimization done by most software compilers like constant propagations, dead code elimination, common subexpression elimination, etc. These optimizations are extremely important because the final hardware circuit might be much larger than necessary if the input description is not optimized. For example, if the code includes (a+b) - (a+b)/8 the synthesizer does not require two adders to compute (a+b) twice as this will not change. The output of the font-end is typical in intermediate representation of the optimized behavioral description in the form of a Control Data Flow Graph (CDFG). This CDFG contain the type of operations and their dependencies in graph format.

* **Stage 2: Main Synthesis Steps:** This stage is the core of the HLS process and can be further decomposed into three main steps: (i) Resource allocation , (ii) Scheduling , and (iii) Binding. The **resource allocation** step extracts the resources in the technology library (ğ‘¡ğ‘’ğ‘â„ğ‘™ğ‘–ğ‘<sub>ğ»ğ¿ğ‘†</sub>) that will be required to synthesize the behavioral description and stores it in a functional unit resource constraint file (FCNT). The **scheduling** step then times the behavioral description based on the available resources in the FCNT file, the target synthesis frequency (ğ‘“<sub>ğ»ğ¿ğ‘†</sub>) and the technology library. Based on the target synthesis frequency and the delay of the individual operators, the same behavioral description will be scheduled into different control/clock steps. This is another advantage of HLS. The same behavioral description is automatically retimed for different target synthesis frequencies and technology libraries, without the need to change the behavioral description. This has the additional benefit that the designer can easily switch between targeting an ASIC and FPGA and quickly evaluate the implementation differences. Finally, the **binding** step determines which operation in the scheduled CDFG is executed onto which of the FUs in the FCNT file. 

* **Stage 3: Back-End:** The back-end stage takes the scheduled and bound CDFG as an input and generates structural RTL code in either Verilog or VHDL as output. The RTL structure generated typical consists of a controller in the form of a Finite State Machine (FSM) and a datapath where the FUs reside. These FUs include, adders, multipliers and dividers of different bit widths.

HLSä¸»è¦æµç¨‹åˆ†ä¸º3ä¸ªé˜¶æ®µï¼šå‰ç«¯ï¼›ç»¼åˆï¼›åç«¯ã€‚å‰ç«¯ä¸»è¦æ˜¯åŸºäºç¼–è¯‘åŸç†å¯¹è¾“å…¥çš„è¡Œä¸ºæè¿°è¿›è¡Œè§£æå’Œä¼˜åŒ–ï¼Œç”Ÿæˆæ§åˆ¶æ•°æ®æµå›¾CDFGï¼ŒHLSç¼–è¯‘å™¨ä¸€èˆ¬æ˜¯åŸºäºLLVM/GCCå®ç°ã€‚ç»¼åˆåˆåˆ†ä¸º3ä¸ªæ­¥éª¤ï¼šèµ„æºåˆ†é…è¿™ä¸€æ­¥æ˜¯è§£ææŠ€æœ¯åº“ä¸­çš„å¯ç”¨èµ„æºå­˜å‚¨åˆ°èµ„æºçº¦æŸæ–‡ä»¶FCNTï¼Œè°ƒåº¦è¿™ä¸€æ­¥æ˜¯åŸºäºç›®æ ‡æ—¶é’Ÿé¢‘ç‡ã€èµ„æºçº¦æŸæ–‡ä»¶ã€æŠ€æœ¯åº“ä¸­ç»„ä»¶å»¶è¿Ÿä¿¡æ¯ç»¼åˆè€ƒè™‘åˆ’åˆ†CDFGä¸­æ¯ä¸ªèŠ‚ç‚¹åˆ°ç›¸åº”çš„clockï¼Œç»‘å®šè¿™ä¸€æ­¥å†³å®šCDFGä¸­æ¯ä¸ªæ“ä½œå¯¹åº”åˆ°FCNTä¸­çš„ç›¸åº”èµ„æºã€‚


### HLSæ ¸å¿ƒæ­¥éª¤

![hls-main](/assets/images/2024-02-04/hls-main.png)

> This figure shows an example of a simple ANSI-C program to be synthesized. In this case the program does two multiplications and two additions taken the variables A,B,C,D as inputs and generates two outputs, E and F. In addition to the behavioral description we can also see the two other inputs required by the HLS process. The technology library (ğ‘¡ğ‘’ğ‘â„ğ‘™ğ‘–ğ‘<sub>ğ»ğ¿ğ‘†</sub>) and the target synthesis frequency, ğ‘“<sub>ğ»ğ¿ğ‘†</sub>.

ä¸Šå›¾æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼šCç¨‹åºæè¿°äº†ä¸€ä¸ªç®€å•ç”µè·¯ï¼Œ4ä¸ªè¾“å…¥2ä¸ªè¾“å‡ºã€‚

> The behavioral description is first parsed by the front-end and the CDFG generated. The next step in most HLS processes is the resource allocation step. This is because most HLS tools perform what is called a resource constrained HLS. In other words, the user specifies how many resources (e.g., functional units) it allows the synthesizer tries to generate the fastest possible circuit given those constraints. Another approach could be to do the exact opposite. Specify the desired performance, e.g., in latency (clock steps required to generate a new output) and the synthesizer would use as many hardware resources as needed to achieve this. The main steps involved in the HLS process are described as follows:

* **Resource allocation:** The HLS process parses the CDFG and extracts from the technology library (ğ‘¡ğ‘’ğ‘â„ğ‘™ğ‘–ğ‘<sub>ğ»ğ¿ğ‘†</sub>) the number and type of operators (FUs) that it needs to execute the operations in the CDFG. The output is thus, a FU constraint file (FCNT) that contains the number and type of FUs. In this particular example the FCNT file includes two 32-bit signed adders and two 32-bit signed multipliers. The main reason for requiring 32-bit FUs is that the variables are declared as integer types (int A,B,C,D). This severely impacts the quality (area and performance) of the generated hardware and thus, it is extremely important to specify the smallest acceptable bit width. It is not the same to have 32-bit adders and multipliers are much larger and have larger delays than 8-bit or 16-bit adders and multipliers. One problem that we can already see is that ANSI-C or C++ only allow to use standard data types, like char, short int, or int, but to fully optimize the hardware circuit, we often need to specify arbitrary bit widths, e.g., 12-bits or 18-bits. To address this, all commercial HLS vendors provide their own custom data types or use SystemC which has been standardize by the IEEE and has its own data
types. 

èµ„æºåˆ†é…è¿™ä¸€æ­¥æ˜¯ç”¨äºä»æŠ€æœ¯åº“ä¸­è§£æå‡ºåŸºæœ¬æ“ä½œçš„ç±»å‹å’Œæ•°é‡ï¼Œç„¶åç”Ÿæˆèµ„æºçº¦æŸæ–‡ä»¶FCNTï¼Œä¸Šå›¾ä¸­çš„FCNTåŒ…æ‹¬2ä¸ª32-bitçš„åŠ æ³•å’Œ2ä¸ª32-bitçš„ä¹˜æ³•ï¼Œä¹‹æ‰€ä»¥æ˜¯32-bitæ˜¯ç”±äºåŸç”Ÿçš„C/C++çš„æ•°æ®ç±»å‹æ— æ³•ç²¾ç¡®æŒ‡å®šbitå®½åº¦ã€‚

* **Scheduling:** This second step parallelizes the CDFG assigning individual parts of it to individual clock steps based on the given constraints. These constraints are the FCNT file generated at the resource allocation stage and the target synthesis frequency, ğ‘“<sub>ğ»ğ¿ğ‘†</sub>. Scheduling is one of the most important parts of the HLS process and much work has been done in the past to find an optimal schedule, although scheduling has been shown to be in general intractable. Because of this, many heuristics that trade-off the quality of the results vs. the time complexity of the scheduler have been presented in the past. Scheduling basically answers the question of how to assign the computations of a program into the hardware time steps.

è°ƒåº¦è¦åšçš„æ˜¯æ ¹æ®FCNTæŠŠCDFGä¸­æ¯ä¸ªæ“ä½œåˆ’åˆ†åˆ°ç›¸åº”çš„æ—¶é’Ÿå‘¨æœŸä»¥æ»¡è¶³ğ‘“<sub>ğ»ğ¿ğ‘†</sub>çš„è¦æ±‚ã€‚å¯å‘å¼è°ƒåº¦ç®—æ³•è¦å¹³è¡¡ç»“æœè´¨é‡å’Œç®—æ³•è€—æ—¶ã€‚

> These scheduling algorithms can be broadly classified into timing-constrained and resource-constrained scheduling. A popular timing-constraint scheduling heuristic algorithm is force-directed scheduling which is based on a constructive heuristic that iteratively tries to minimize the force of the scheduled operations to balance the computations on the given clock steps in order to minimize the number of hardware resources used. Most modern HLS synthesizers perform resource-constraint scheduling, where the number of FU are first constraints and the goal is to find the fastest possible circuit. One of the most popular heuristic is list scheduling, where operations are sorted in a list according to a given priority function and then scheduled in the sorted order in the next available clock step. More recently a more elegant way to formulate the scheduling program as a Integer Linear Program (ILP) through a sum of difference constraint (SDC). This can then be passed to an ILP solver which can return the optimal solution.

è°ƒåº¦ç®—æ³•åˆ†ä¸ºæ—¶é—´å—é™å’Œèµ„æºå—é™ä¸¤ç±»ï¼Œæ—¶é—´å—é™ç®—æ³•æ˜¯ç”¨äºè®¡ç®—åœ¨æ»¡è¶³æ—¶é—´çº¦æŸæ—¶ä½¿ç”¨æœ€å°‘èµ„æºçš„ç”µè·¯ï¼Œèµ„æºå—é™ç®—æ³•æ˜¯ç”¨äºè®¡ç®—ä½¿ç”¨æœ‰é™çš„èµ„æºäº§ç”Ÿæœ€å¿«çš„ç”µè·¯ã€‚å·¥ä¸šä¸Šå¸¸ç”¨çš„æ˜¯èµ„æºè°ƒåº¦ç®—æ³•ï¼Œå¸¸ç”¨çš„è°ƒåº¦ç®—æ³•æœ‰3ç§: ASAP, ALAPå’Œ SDCã€‚

**As Soon As Possible (ASAP) Scheduling:** One of the easiest way to schedule the CDFG is using an ASAP technique. This technique basically schedules every operation as soon as it is possible. One of the advantages of the ASAP algorithm is that it leads to the optimal solution if the scheduler is allowed to use an infinite number of resources (basically no resource constraint). ASAP scheduling maps operations to their earliest possible start time without violating the precedence constraint. Here is a list of the main characteristics of ASAP scheduling:

1. East and fast to compute. Scheduling can be extremely complex and time consuming. ASAP is very fast.
2. ASAP scheduling does not attempt to optimize the number of resources used.
3. Gives the shortest (fastest) possible schedule if unlimited amount of resources is available. 
4. Gives an upper bound of the execution time.

![hls-sched-asap](/assets/images/2024-02-04/hls-sched-asap.png)

ç¤ºä¾‹å¦‚ä¸Šå›¾ï¼Œç”±äºFCNTé™å®šäº†æœ‰2ä¸ªåŠ æ³•1ä¸ªä¹˜æ³•ï¼Œæ‰€ä»¥ä¹Ÿé™å®šäº†ä¸€ä¸ªå‘¨æœŸå†…æœ€å¤§å¯ä½¿ç”¨çš„èµ„æºï¼Œç„¶åå†æ ¹æ®æŠ€æœ¯åº“é‡Œæ¯ä¸ªåŸºæœ¬æ“ä½œçš„å»¶è¿Ÿå‚æ•°å’Œæ—¶é’Ÿé¢‘ç‡çš„è¦æ±‚åˆ†å‰²CDFGä¸­çš„æ¯ä¸ªæ“ä½œã€‚

**As Late As Possible (ALAP) Scheduling:** In ALAP scheduling the operations are mapped to their latest possible start time not violating the precedence constraints. Here is a list of the main characteristics of ALAP scheduling:

1. Easy and fast to compute
2. Finds the longest path in a directed acyclic graph
3. Does not attempt to optimize the resource cost similar to ASAP

![hls-sched-alap](/assets/images/2024-02-04/hls-sched-alap.png)

ä¸Šå›¾æ˜¯ALAPçš„ç¤ºä¾‹ï¼Œä¸ASAPç›¸æ¯”ç¬¬äºŒä¸ªåŠ æ³•å‘ä¸‹ç§»åŠ¨åˆ°å³å°†ä½¿ç”¨ä¹‹å‰ã€‚ASAPå¯ä»¥ç§°ä½œæ˜¯å‹¤å¿«æ¨¡å¼ï¼Œåˆ©ç”¨æœ‰é™çš„èµ„æºèƒ½å¹²å¤šå°‘å¹²å¤šå°‘ï¼Œå°½å¿«å¹²å®Œï¼›ALAPå¯ä»¥ç§°ä½œæ˜¯ä¾èµ–æ¨¡å¼ï¼Œåˆ©ç”¨æœ‰é™çš„èµ„æºå°½å¯èƒ½çš„å…ˆå¹²è¢«ä¾èµ–ä¸”æ— ä¾èµ–çš„æ“ä½œã€‚

**Sum of Difference Constraint (SDC) Scheduling:** In SDC scheduling the scheduling problem is formulated as a mathematical optimization problem that is then solved through a solver. More specifically as in integer linear problem (ILP). This makes it possible to solve the schedule formulation in polynomial time (fast). The formulation is basically a linear objective function with linear constraints (e.g.,==,<=, >=). In SDC scheduling every operation in the DFG is assigned a variable. The dependencies between the different operations (variables) are then formulated as equations, hence the name difference constraints. Here is a list of the main characteristics of the SDC scheduling technique:

1. Optimizes the latency often leading to the optimal results and better results than previous methods.
2. Fast solution as can be solved in polynomial time.

![hls-sched-sdc](/assets/images/2024-02-04/hls-sched-sdc.png)

ä¸Šå›¾æ˜¯SDCç®—æ³•çš„ç¤ºä¾‹ï¼ŒSDCç®—æ³•æŠŠé—®é¢˜è½¬æ¢ä¸ºæ•°å­¦é—®é¢˜ï¼Œç±»ä¼¼äºçº¿æ€§å›å½’ï¼Œç”¨æ•°å­¦çš„æ–¹å¼æ±‚æœ€ä¼˜è§£ã€‚ä¸Šå›¾ç¤ºä¾‹åˆ†æˆ6ä¸ªæ­¥éª¤ã€‚

1. **Assign variable to every operator:** Assign each operation in the DFG a variable name. In this example the first adder is ğ‘‹ğ‘ğ‘‘ğ‘‘1, the second adder ğ‘‹ğ‘ğ‘‘ğ‘‘2, and the multipliers are ğ‘‹ğ‘šğ‘¢ğ‘™1 and ğ‘‹ğ‘šğ‘¢ğ‘™2.

2. **Dependencies constraints:** Model the dependencies in the DFG mathematically as difference constraints equations.

3. **Handling clock constraints:** Update the difference constraint equations based on ğ‘“ğ»ğ¿ğ‘† and the delay of the different operations

4. **Handling Resource constraints:** Create a topological sorted list of the resource constrained operations. Model the constraint as another difference constraint equation and add it to the previous equations.

5. **Formulated cost function:** Formulate the overall cost function that needs to minimize the sum of the variables in the system, subject to all the constraints generated.

6. **Run Solver:** Call the solver used to obtain the schedule of each operation clock step in which is operation is scheduled will be reported if a valid schedule is possible.


* **Binding:** This last step assigns the different operations in the scheduled CDFG to the different FUs in the FCNT file. In this case because we have two adders and two multipliers, the binding stage has to decide which adder and multiplier will execute which operation. Although this might seem trivial, the binder needs to make sure that the operations across the entire scheduled circuit are balanced as these FUs will be shared across multiple operations which requires multiplexers.

æœ€åä¸€æ­¥ç»‘å®šæ˜¯æœ€ç»ˆçš„CDFGçš„æ¯ä¸ªèŠ‚ç‚¹ç»‘å®šåˆ°FCNTä¸­çš„èµ„æºä¸Šã€‚


### Back-end: RTL Generation

![hls-rtl](/assets/images/2024-02-04/hls-rtl.png)

> The typical circuit has a FSM and a data path. The data path contains the FUs generated in the resource allocation stage. Because these FUs are shared for different operations in the code, muxes are inserted before and after. An FSM is also generated to generate the control signals for these muxes in order to steer the data across the data path accordingly.

å…¸å‹çš„ç”µè·¯åŒ…å«FSMå’Œæ•°æ®è·¯å¾„ï¼Œåœ¨æ“ä½œå‡ºç°å…±äº«æ—¶æ’å…¥muxï¼Œæ ¹æ®FSMæ¥æ§åˆ¶muxã€‚
